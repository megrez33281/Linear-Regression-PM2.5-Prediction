# HW1:PM2.5預測計畫 

## 階段一：資料前處理(Data Preprocessing)
此階段的目標是將原始資料轉換為乾淨、可用於模型訓練的格式
1. 資料清理
	目標：處理原始資料中的無效觀測值
	作法：
		讀取train.csv，處理其中的無效值，例如 #,*,x,A
		以內插法預測其中的值（考慮到有些特徵的0有特殊涵意，如：0度C，因此此處不以補0的方式解決）

2. 資料重塑(Data Reshaping)
	目標：將時序資料轉換為監督式學習樣本
	作法：
		將連續時間格式的訓練資料，以Sliding Window的方式轉換為「前9小時數據作為特徵，第10小時PM2.5作為目標」的樣本格式
		如：
			第一筆數據：
				Input(X)：小時1到9的數據 
				Target(y)：第10小時的PM2.5 
			第二筆數據：
				Input(X)：小時2到10的數據 
				Target(y)：第11小時的PM2.5 

3. 特徵標準化(Feature Standardization)
	目標：統一所有特徵的數值尺度，加速模型收斂
	作法：
		對所有特徵進行標準化(Standardization)，將他們縮放到同一尺度


## 階段二：特徵篩選(Feature Engineering & Selection)
此階段的目標是從原始數據中萃取出最有預測能力的特徵組合
兩個方法中：
	方法一：
		將各個特徵與PM2.5分別進行視覺化分析，找到最有關係的特徵
	方法二：
		利用L1正規化(Lasso)找到合適的特徵組合
		基於L1的特性，在訓練過程中，會將不重要的特徵權重壓成0，保留重要特徵
		
基於方法一需要一定領域相關知識以及一個一個視覺化比較繁瑣，且選擇方法二可以以模組化的方式重複使用程式碼，因此此處選擇使用方法二
	
1. 核心特徵識別
	目標：由於後續要對特徵進行組合，為了避免參與篩選的特徵過多，因此要先找出對預測PM2.5最有影響力的原始特徵
	作法：
		1. 計算相關係數矩陣
		2. 提取所有特徵與PM2.5的相關性
		3. 取絕對值後（無論正負）按相關性強度進行降序排序
		4. 選出TopN特徵
		
2. 候選特徵生成
	目標：生成一批有潛力的組合特徵，同樣為了避免特徵爆炸，只選擇原始特徵、兩兩相乘、平方項（新特徵）
	作法：
		* 二次方項：為這5-8個核心特徵生成平方項
		* 交互項：在這5-8個核心特徵之間，建立兩兩相乘的交互項
		* 建立特徵池：將Top 5-8的原始特徵+生成的二次方項+生成的交互項合併成一個完整的候選特徵池（矩陣）

3. Lasso(L1)特徵篩選
	目標：從候選特徵池中自動化挑選出最有價值的特徵組合
	作法：
		以候選特徵池為輸入，訓練一個Lasso Regression模型
		透過調整正規化參數λ，找出一個能有效篩選出稀疏（部分權重為零）且強大特徵集的模型

4. 最終特徵集確立
	目標：確立最終用於訓練預測模型的特徵集
	作法：
		紀錄Lasso模型中所有權重不為零的特徵項，此即要用於最終訓練的特徵（需要紀錄最終採用的特徵，如：(CO)^2、(CH4*CO)......，後續進行inference時可以直接抽取特徵）

## 階段三：模型訓練(Model Training)
此階段的目標是使用篩選出的特徵集，訓練出一個最佳的預測模型
1. 模型架構
	模型：線性迴歸(Linear Regression)
	實作：根據作業要求，模型核心演算法必須僅使用Numpy實作 

2. 損失函數
	函式：MSE(均方誤差) + 正規化項
	說明：
		由於評分指標為RMSE ，可以用優化MSE的方式進行
		相較於篩選特徵時使用L1（Lasso）進進行正規劃，此處用L2(Ridge)正規化以獲取穩定性，並重新為此模型尋找一個最佳的λ

3. 優化演算法
	演算法：隨機梯度下降法(Stochastic Gradient Descent, SGD)
	說明：
		相較於一次計算所有樣本的批次梯度下降，SGD每次只用一個或一小批樣本來更新權重，訓練速度更快

4. 學習率調整
	方法：Adagrad
	說明：
		採用Adagrad演算法，為每個參數自動調整學習率

## 階段四：預測與提交(Prediction & Submission)
此階段的目標是利用訓練好的模型完成預測並產出提交檔案
1. 測試資料處理
	作法：
		讀取test.csv，並對其進行與訓練資料完全相同的前處理
		並依照特徵篩選步驟得到的特徵組合進行特徵抽取

2. 執行預測
	作法：使用在階段三訓練好的最終模型，對處理過的測試資料進行預測

3. 產出提交檔案
	作法：將預測結果整理成Kaggle要求的大小為245x2的CSV格式，欄位名稱為index和answer